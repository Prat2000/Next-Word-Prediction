{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"NextWordPredict4_multi_BiLSTM.ipynb","provenance":[{"file_id":"1NvOa-oNaKOsMYINPqHDJgQEsa5QHOM-C","timestamp":1617599578814},{"file_id":"1P6e8t1lBfgWrKbNogT1yVyLIAojuibLs","timestamp":1614945618376}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"k9cKBRcagyql"},"source":["**Model Training**"]},{"cell_type":"code","metadata":{"id":"Itxm0-zeqk8K"},"source":["!rm -rf '/content/sample_data'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qaCQAatTxyv3"},"source":["from tensorflow.keras.layers import Embedding,LSTM,Dense,Bidirectional\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.models import clone_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZFt4gJVKsLwk","executionInfo":{"status":"ok","timestamp":1623399097003,"user_tz":-330,"elapsed":2085,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"2ff5802e-b762-48b7-ebf5-3c59ca980a44"},"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import numpy as np\n","import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"9ikKCvAlF468"},"source":["Step<br>\n","Read \"Metmorphosis\" Dataset"]},{"cell_type":"code","metadata":{"id":"8YCiGOAK8gaP"},"source":["file=open(\"metamorphosis_clean.txt\",mode='rt',encoding=\"utf8\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FPEqQdt_EcaG"},"source":["line=[]\n","for i in file:\n","  line.append(i)\n","data=\"\"\n","for i in line:\n","  data=' '.join(line) \n","data=data.replace('\\n','').replace('\\r','').replace('\\ufeff','')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xFll2ihXGGhr"},"source":["Step:<br>\n","1.Split dataset into list of words <br>\n","2.All words in lower case"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mq3MwHnsq1GW","executionInfo":{"status":"ok","timestamp":1623399101375,"user_tz":-330,"elapsed":1519,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"8b7b09ab-2c72-4ab5-81c3-68dd67405d51"},"source":["z=word_tokenize(data)\n","z=[word.lower() for word in z if word.isalpha()]\n","z[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['one', 'morning', 'when', 'gregor', 'samsa']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"RSICjvKnfQxp"},"source":["**Dataset model_1**"]},{"cell_type":"markdown","metadata":{"id":"wqEXyw7tGf0f"},"source":["Step:<br>\n","1. Divide dataset into sets of 5 words\n","2. 5 words consist of 4 training words + 1 target word"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vk1V77eXsSk_","executionInfo":{"status":"ok","timestamp":1623399101376,"user_tz":-330,"elapsed":9,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"85f42060-ae8d-4393-b053-bc47abbfb7ea"},"source":["train_size=5\n","pred_size=1\n","text_to_train=[]\n","for i in range(train_size,len(z)):\n","  word_set=z[i-train_size:i]\n","  text_to_train.append(word_set)\n","print(text_to_train[:3])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['one', 'morning', 'when', 'gregor', 'samsa'], ['morning', 'when', 'gregor', 'samsa', 'woke'], ['when', 'gregor', 'samsa', 'woke', 'from']]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iuRjPOqRG_eM"},"source":["Step:<br>\n","1. Use tokenizer to convert text into sequences\n","2. Separate training words and target word\n","3. One-hot encode target word based on dictionary"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N_C9kW_ptUUP","executionInfo":{"status":"ok","timestamp":1623399104246,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"ca978acf-bea6-4781-bc1a-acba85feebcb"},"source":["tokenizer=Tokenizer()\n","tokenizer.fit_on_texts(text_to_train)\n","text_sequence=tokenizer.texts_to_sequences(text_to_train)\n","print(text_sequence[:3])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[63, 144, 54, 12, 93], [144, 54, 12, 93, 899], [54, 12, 93, 899, 29]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRUwy_xtvUIM","executionInfo":{"status":"ok","timestamp":1623399104876,"user_tz":-330,"elapsed":6,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"785ed73b-c2f4-45a2-ec29-f396f8124a79"},"source":["vocab_size=len(tokenizer.word_index)+1\n","\n","text_sequence=np.array(text_sequence)\n","data=text_sequence[:,:-pred_size]\n","target_data=text_sequence[:,-pred_size:]\n","print(text_sequence[:3])\n","print(data[:3,:])\n","print(target_data[:3,:])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 63 144  54  12  93]\n"," [144  54  12  93 899]\n"," [ 54  12  93 899  29]]\n","[[ 63 144  54  12]\n"," [144  54  12  93]\n"," [ 54  12  93 899]]\n","[[ 93]\n"," [899]\n"," [ 29]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qDfdQYM_HcO0"},"source":["Dictionary (Total vocabulary)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_9HHa4hDL10","executionInfo":{"status":"ok","timestamp":1623399108858,"user_tz":-330,"elapsed":10,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"5cb01ff7-e046-44b7-915a-fa38453bc73e"},"source":["my_vocab=dict([value,key] for key,value in tokenizer.word_index.items())\n","print(my_vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{1: 'the', 2: 'to', 3: 'and', 4: 'he', 5: 'his', 6: 'of', 7: 'was', 8: 'it', 9: 'had', 10: 'in', 11: 'that', 12: 'gregor', 13: 'a', 14: 'as', 15: 'she', 16: 'with', 17: 'would', 18: 'him', 19: 'her', 20: 'not', 21: 'but', 22: 'at', 23: 'for', 24: 'they', 25: 'on', 26: 'all', 27: 'room', 28: 'could', 29: 'from', 30: 'be', 31: 'out', 32: 'have', 33: 'there', 34: 'if', 35: 'father', 36: 'been', 37: 'sister', 38: 'so', 39: 'this', 40: 'i', 41: 'now', 42: 'mother', 43: 'himself', 44: 'door', 45: 'then', 46: 'did', 47: 'back', 48: 'up', 49: 'even', 50: 'into', 51: 'what', 52: 'more', 53: 'their', 54: 'when', 55: 'were', 56: 'about', 57: 'them', 58: 'way', 59: 'only', 60: 'you', 61: 'time', 62: 'no', 63: 'one', 64: 'do', 65: 'by', 66: 'than', 67: 'just', 68: 'said', 69: 'little', 70: 'any', 71: 'other', 72: 'get', 73: 'still', 74: 'first', 75: 'or', 76: 'made', 77: 'go', 78: 'some', 79: 'while', 80: 'see', 81: 'again', 82: 'without', 83: 'head', 84: 'before', 85: 'much', 86: 'after', 87: 'where', 88: 'chief', 89: 'clerk', 90: 'like', 91: 'down', 92: 'open', 93: 'samsa', 94: 'which', 95: 'very', 96: 'we', 97: 'who', 98: 'thought', 99: 'over', 100: 'went', 101: 'come', 102: 'away', 103: 'family', 104: 'an', 105: 'soon', 106: 'well', 107: 'came', 108: 'left', 109: 'too', 110: 'quite', 111: 'is', 112: 'let', 113: 'though', 114: 'bed', 115: 'looked', 116: 'how', 117: 'everything', 118: 'something', 119: 'day', 120: 'wanted', 121: 'against', 122: 'two', 123: 'seemed', 124: 'parents', 125: 'being', 126: 'work', 127: 'round', 128: 'things', 129: 'three', 130: 'grete', 131: 'gentlemen', 132: 'able', 133: 'because', 134: 'make', 135: 'body', 136: 'already', 137: 'really', 138: 'look', 139: 'slowly', 140: 'long', 141: 'side', 142: 'floor', 143: 'hand', 144: 'morning', 145: 'onto', 146: 'got', 147: 'my', 148: 'legs', 149: 'used', 150: 'never', 151: 'better', 152: 'enough', 153: 'think', 154: 'through', 155: 'flat', 156: 'around', 157: 'lay', 158: 'off', 159: 'although', 160: 'table', 161: 'turned', 162: 'window', 163: 'heard', 164: 'feel', 165: 'right', 166: 'eyes', 167: 'home', 168: 'become', 169: 'hands', 170: 'under', 171: 'here', 172: 'good', 173: 'its', 174: 'whole', 175: 'longer', 176: 'always', 177: 'must', 178: 'began', 179: 'once', 180: 'possible', 181: 'next', 182: 'perhaps', 183: 'nothing', 184: 'almost', 185: 'took', 186: 'say', 187: 'evening', 188: 'straight', 189: 'living', 190: 'herself', 191: 'me', 192: 'know', 193: 'should', 194: 'voice', 195: 'each', 196: 'might', 197: 'front', 198: 'couch', 199: 'hardly', 200: 'your', 201: 'can', 202: 'move', 203: 'same', 204: 'help', 205: 'opened', 206: 'immediately', 207: 'asked', 208: 'chair', 209: 'women', 210: 'behind', 211: 'happened', 212: 'times', 213: 'felt', 214: 'business', 215: 'probably', 216: 'often', 217: 'became', 218: 'course', 219: 'also', 220: 'taken', 221: 'sat', 222: 'sleep', 223: 'doing', 224: 'food', 225: 'these', 226: 'chest', 227: 'put', 228: 'called', 229: 'anything', 230: 'arms', 231: 'held', 232: 'stood', 233: 'attention', 234: 'pressed', 235: 'face', 236: 'furniture', 237: 'found', 238: 'life', 239: 'close', 240: 'money', 241: 'certainly', 242: 'seen', 243: 'hear', 244: 'until', 245: 'playing', 246: 'towards', 247: 'hard', 248: 'tried', 249: 'pushed', 250: 'saw', 251: 'quickly', 252: 'especially', 253: 'later', 254: 'words', 255: 'done', 256: 'forward', 257: 'new', 258: 'every', 259: 'leave', 260: 'reason', 261: 'understand', 262: 'take', 263: 'old', 264: 'violin', 265: 'making', 266: 'boss', 267: 'thing', 268: 'moving', 269: 'set', 270: 'ever', 271: 'want', 272: 'give', 273: 'most', 274: 'keep', 275: 'last', 276: 'stay', 277: 'moved', 278: 'remained', 279: 'least', 280: 'us', 281: 'kitchen', 282: 'clear', 283: 'ran', 284: 'key', 285: 'eat', 286: 'middle', 287: 'moment', 288: 'state', 289: 'however', 290: 'pain', 291: 'effort', 292: 'own', 293: 'whether', 294: 'doors', 295: 'night', 296: 'themselves', 297: 'finally', 298: 'despite', 299: 'will', 300: 'quiet', 301: 'few', 302: 'great', 303: 'turn', 304: 'looking', 305: 'upright', 306: 'covered', 307: 'shut', 308: 'stopped', 309: 'train', 310: 'told', 311: 'desk', 312: 'together', 313: 'another', 314: 'drawers', 315: 'seven', 316: 'completely', 317: 'noticed', 318: 'carefully', 319: 'dressed', 320: 'fell', 321: 'ca', 322: 'clearly', 323: 'use', 324: 'far', 325: 'why', 326: 'suddenly', 327: 'since', 328: 'tears', 329: 'realised', 330: 'taking', 331: 'going', 332: 'everyone', 333: 'charwoman', 334: 'cleaner', 335: 'slightly', 336: 'travelling', 337: 'present', 338: 'position', 339: 'anyone', 340: 'place', 341: 'are', 342: 'eating', 343: 'notice', 344: 'fall', 345: 'half', 346: 'yes', 347: 'noise', 348: 'having', 349: 'need', 350: 'word', 351: 'peace', 352: 'bring', 353: 'sign', 354: 'others', 355: 'force', 356: 'kept', 357: 'loud', 358: 'maid', 359: 'across', 360: 'needed', 361: 'knew', 362: 'hours', 363: 'speak', 364: 'please', 365: 'else', 366: 'nearly', 367: 'job', 368: 'condition', 369: 'hurried', 370: 'lock', 371: 'mouth', 372: 'leant', 373: 'several', 374: 'uniform', 375: 'finished', 376: 'doorway', 377: 'closed', 378: 'stand', 379: 'rest', 380: 'between', 381: 'walls', 382: 'spread', 383: 'nice', 384: 'lower', 385: 'god', 386: 'different', 387: 'white', 388: 'getting', 389: 'during', 390: 'maybe', 391: 'years', 392: 'man', 393: 'doctor', 394: 'hurriedly', 395: 'near', 396: 'full', 397: 'conversation', 398: 'both', 399: 'breakfast', 400: 'instead', 401: 'serious', 402: 'difficult', 403: 'part', 404: 'turning', 405: 'carry', 406: 'earlier', 407: 'order', 408: 'calm', 409: 'expected', 410: 'sound', 411: 'question', 412: 'simply', 413: 'easy', 414: 'strength', 415: 'knowing', 416: 'sight', 417: 'hall', 418: 'kind', 419: 'breath', 420: 'ground', 421: 'chance', 422: 'reached', 423: 'pleasure', 424: 'end', 425: 'fully', 426: 'light', 427: 'ceiling', 428: 'actually', 429: 'dish', 430: 'sometimes', 431: 'music', 432: 'totally', 433: 'tired', 434: 'crawl', 435: 'lifted', 436: 'picture', 437: 'forget', 438: 'unable', 439: 'sleeping', 440: 'oh', 441: 'people', 442: 'early', 443: 'whenever', 444: 'try', 445: 'given', 446: 'tell', 447: 'sort', 448: 'five', 449: 'alarm', 450: 'past', 451: 'quarter', 452: 'fresh', 453: 'office', 454: 'wrong', 455: 'struck', 456: 'leaving', 457: 'aware', 458: 'habit', 459: 'lying', 460: 'caused', 461: 'slightest', 462: 'free', 463: 'painfully', 464: 'air', 465: 'unfortunately', 466: 'street', 467: 'carpet', 468: 'find', 469: 'someone', 470: 'anyway', 471: 'sure', 472: 'year', 473: 'gave', 474: 'listen', 475: 'listening', 476: 'hold', 477: 'meal', 478: 'landing', 479: 'earn', 480: 'impossible', 481: 'foot', 482: 'rushed', 483: 'lost', 484: 'forgotten', 485: 'running', 486: 'flew', 487: 'milk', 488: 'crawling', 489: 'days', 490: 'bent', 491: 'sheet', 492: 'meant', 493: 'many', 494: 'human', 495: 'cut', 496: 'threw', 497: 'friendly', 498: 'overcome', 499: 'gone', 500: 'pay', 501: 'clock', 502: 'quietly', 503: 'rush', 504: 'ill', 505: 'fact', 506: 'usual', 507: 'shocked', 508: 'outside', 509: 'short', 510: 'sides', 511: 'throw', 512: 'learned', 513: 'easily', 514: 'followed', 515: 'harder', 516: 'consideration', 517: 'raised', 518: 'happen', 519: 'patient', 520: 'locked', 521: 'steps', 522: 'necessary', 523: 'show', 524: 'stayed', 525: 'idea', 526: 'glad', 527: 'seriously', 528: 'speaking', 529: 'late', 530: 'beside', 531: 'alright', 532: 'nobody', 533: 'wait', 534: 'loudly', 535: 'holding', 536: 'using', 537: 'start', 538: 'disappeared', 539: 'along', 540: 'wall', 541: 'enormous', 542: 'urge', 543: 'spare', 544: 'stick', 545: 'pulled', 546: 'stop', 547: 'allowed', 548: 'intentions', 549: 'slammed', 550: 'filled', 551: 'either', 552: 'forced', 553: 'surprise', 554: 'carried', 555: 'startled', 556: 'asleep', 557: 'broom', 558: 'send', 559: 'indeed', 560: 'silent', 561: 'slow', 562: 'coming', 563: 'writing', 564: 'immobile', 565: 'shouted', 566: 'apple', 567: 'sit', 568: 'appeared', 569: 'gentleman', 570: 'brown', 571: 'ready', 572: 'small', 573: 'four', 574: 'above', 575: 'hung', 576: 'lady', 577: 'fur', 578: 'hat', 579: 'raising', 580: 'heavy', 581: 'arm', 582: 'bit', 583: 'slight', 584: 'drew', 585: 'touched', 586: 'live', 587: 'ought', 588: 'best', 589: 'talking', 590: 'hope', 591: 'change', 592: 'forwards', 593: 'catch', 594: 'entirely', 595: 'somebody', 596: 'somewhere', 597: 'answer', 598: 'saying', 599: 'gently', 600: 'answered', 601: 'remove', 602: 'disturbed', 603: 'thoughts', 604: 'sensible', 605: 'today', 606: 'push', 607: 'those', 608: 'itself', 609: 'trying', 610: 'direction', 611: 'hit', 612: 'pushing', 613: 'whatever', 614: 'view', 615: 'confidence', 616: 'entire', 617: 'concern', 618: 'strong', 619: 'mind', 620: 'careful', 621: 'call', 622: 'difficulty', 623: 'smile', 624: 'decision', 625: 'highly', 626: 'employees', 627: 'annoyed', 628: 'fallen', 629: 'has', 630: 'evenings', 631: 'working', 632: 'amazed', 633: 'worry', 634: 'happening', 635: 'astonished', 636: 'seem', 637: 'animal', 638: 'entrance', 639: 'locksmith', 640: 'skirts', 641: 'situation', 642: 'teeth', 643: 'lack', 644: 'break', 645: 'wide', 646: 'movement', 647: 'reading', 648: 'exactly', 649: 'respect', 650: 'our', 651: 'started', 652: 'stretched', 653: 'save', 654: 'mood', 655: 'future', 656: 'talk', 657: 'backwards', 658: 'newspaper', 659: 'drive', 660: 'merely', 661: 'obviously', 662: 'dark', 663: 'crawled', 664: 'darkness', 665: 'such', 666: 'waited', 667: 'empty', 668: 'nonetheless', 669: 'spent', 670: 'bear', 671: 'anxiously', 672: 'rather', 673: 'feet', 674: 'brought', 675: 'month', 676: 'breathe', 677: 'becoming', 678: 'dinner', 679: 'fetch', 680: 'decided', 681: 'appearance', 682: 'high', 683: 'stepped', 684: 'broke', 685: 'arrived', 686: 'coat', 687: 'pockets', 688: 'friends', 689: 'bedroom', 690: 'briefly', 691: 'corner', 692: 'rented', 693: 'rid', 694: 'horrible', 695: 'belly', 696: 'stiff', 697: 'proper', 698: 'peacefully', 699: 'samples', 700: 'recently', 701: 'showed', 702: 'rain', 703: 'sad', 704: 'rolled', 705: 'top', 706: 'bad', 707: 'lift', 708: 'cold', 709: 'slid', 710: 'salesmen', 711: 'sitting', 712: 'spot', 713: 'ago', 714: 'hearing', 715: 'debt', 716: 'six', 717: 'big', 718: 'true', 719: 'deeply', 720: 'lively', 721: 'avoid', 722: 'anger', 723: 'report', 724: 'understanding', 725: 'extremely', 726: 'suspicious', 727: 'yet', 728: 'company', 729: 'apart', 730: 'knock', 731: 'deep', 732: 'inside', 733: 'mixed', 734: 'properly', 735: 'explanation', 736: 'knocking', 737: 'opening', 738: 'consider', 739: 'remembered', 740: 'simple', 741: 'broad', 742: 'directions', 743: 'control', 744: 'managed', 745: 'weight', 746: 'occurred', 747: 'injured', 748: 'afraid', 749: 'watching', 750: 'bringing', 751: 'narrow', 752: 'lightly', 753: 'total', 754: 'ask', 755: 'falling', 756: 'raise', 757: 'forth', 758: 'caught', 759: 'firm', 760: 'spend', 761: 'upset', 762: 'wants', 763: 'town', 764: 'explaining', 765: 'silence', 766: 'crying', 767: 'intention', 768: 'suitable', 769: 'behaviour', 770: 'causing', 771: 'employer', 772: 'immediate', 773: 'am', 774: 'giving', 775: 'wish', 776: 'nor', 777: 'waste', 778: 'learn', 779: 'sir', 780: 'shocking', 781: 'suffer', 782: 'sent', 783: 'calmly', 784: 'contrast', 785: 'drawn', 786: 'meanwhile', 787: 'flowed', 788: 'following', 789: 'efforts', 790: 'occupied', 791: 'hair', 792: 'line', 793: 'large', 794: 'important', 795: 'remember', 796: 'usually', 797: 'partly', 798: 'shoulders', 799: 'secret', 800: 'sudden', 801: 'waiting', 802: 'convinced', 803: 'provide', 804: 'persuade', 805: 'understood', 806: 'landed', 807: 'outstretched', 808: 'sake', 809: 'coffee', 810: 'fled', 811: 'relatively', 812: 'picked', 813: 'appeals', 814: 'hissing', 815: 'distance', 816: 'further', 817: 'fast', 818: 'shove', 819: 'heavily', 820: 'feeling', 821: 'smell', 822: 'normally', 823: 'enter', 824: 'remain', 825: 'uneasy', 826: 'regret', 827: 'hunger', 828: 'greatest', 829: 'test', 830: 'watched', 831: 'realise', 832: 'bare', 833: 'cheese', 834: 'comfortable', 835: 'liked', 836: 'finger', 837: 'eaten', 838: 'midday', 839: 'news', 840: 'delay', 841: 'ate', 842: 'misfortune', 843: 'despair', 844: 'success', 845: 'earned', 846: 'warm', 847: 'fond', 848: 'conservatory', 849: 'christmas', 850: 'continue', 851: 'pull', 852: 'repeated', 853: 'lot', 854: 'interest', 855: 'nodded', 856: 'closer', 857: 'strain', 858: 'sofa', 859: 'child', 860: 'clothes', 861: 'experienced', 862: 'easier', 863: 'carrying', 864: 'improvement', 865: 'letting', 866: 'entertaining', 867: 'dare', 868: 'thrown', 869: 'insist', 870: 'admit', 871: 'changed', 872: 'chase', 873: 'screamed', 874: 'shaking', 875: 'death', 876: 'mean', 877: 'standing', 878: 'gold', 879: 'buttons', 880: 'cap', 881: 'movements', 882: 'contrary', 883: 'absolutely', 884: 'dust', 885: 'clean', 886: 'chairs', 887: 'play', 888: 'beards', 889: 'hurry', 890: 'smiled', 891: 'played', 892: 'hallway', 893: 'neck', 894: 'dead', 895: 'daughter', 896: 'letters', 897: 'stretch', 898: 'young', 899: 'woke', 900: 'dreams', 901: 'thin', 902: 'size', 903: 'dream', 904: 'familiar', 905: 'collection', 906: 'salesman', 907: 'frame', 908: 'fitted', 909: 'dull', 910: 'weather', 911: 'drops', 912: 'hitting', 913: 'pane', 914: 'chosen', 915: 'curse', 916: 'worries', 917: 'itch', 918: 'makes', 919: 'stupid', 920: 'instance', 921: 'house', 922: 'breakfasts', 923: 'definitely', 924: 'rung', 925: 'slept', 926: 'mad', 927: 'particularly', 928: 'assistant', 929: 'fifteen', 930: 'service', 931: 'accuse', 932: 'son', 933: 'hungrier', 934: 'cautious', 935: 'painful', 936: 'explain', 937: 'circumstances', 938: 'wooden', 939: 'members', 940: 'fist', 941: 'putting', 942: 'individual', 943: 'whispered', 944: 'beg', 945: 'acquired', 946: 'conclusions', 947: 'matter', 948: 'covers', 949: 'blow', 950: 'moreover', 951: 'bend', 952: 'imagine', 953: 'gather', 954: 'sensitive', 955: 'eventually', 956: 'miracle', 957: 'price', 958: 'sacrifice', 959: 'remind', 960: 'direct', 961: 'fog', 962: 'breathing', 963: 'real', 964: 'task', 965: 'main', 966: 'load', 967: 'swang', 968: 'ten', 969: 'froze', 970: 'visitor', 971: 'couple', 972: 'enquiries', 973: 'innocent', 974: 'rubbed', 975: 'reply', 976: 'polished', 977: 'boots', 978: 'continued', 979: 'believe', 980: 'week', 981: 'paper', 982: 'relaxation', 983: 'fretsaw', 984: 'hanging', 985: 'ourselves', 986: 'stubborn', 987: 'unwell', 988: 'fortunately', 989: 'cry', 990: 'danger', 991: 'abandoning', 992: 'excuse', 993: 'sacked', 994: 'worried', 995: 'yourself', 996: 'unnecessary', 997: 'fail', 998: 'unheard', 999: 'behalf', 1000: 'person', 1001: 'showing', 1002: 'failure', 1003: 'appear', 1004: 'stubbornness', 1005: 'intended', 1006: 'cause', 1007: 'grant', 1008: 'forgetting', 1009: 'attack', 1010: 'staying', 1011: 'eight', 1012: 'insistent', 1013: 'curious', 1014: 'climb', 1015: 'swing', 1016: 'tightly', 1017: 'calmed', 1018: 'surely', 1019: 'cried', 1020: 'quick', 1021: 'spoke', 1022: 'anna', 1023: 'girls', 1024: 'surprising', 1025: 'judge', 1026: 'whispering', 1027: 'adhesive', 1028: 'rested', 1029: 'grasp', 1030: 'jaw', 1031: 'ignoring', 1032: 'damage', 1033: 'excitedly', 1034: 'concentration', 1035: 'handle', 1036: 'double', 1037: 'entering', 1038: 'sounded', 1039: 'driven', 1040: 'steady', 1041: 'unfolded', 1042: 'sank', 1043: 'fists', 1044: 'wanting', 1045: 'shook', 1046: 'bolted', 1047: 'hospital', 1048: 'windows', 1049: 'piercing', 1050: 'washing', 1051: 'newspapers', 1052: 'opposite', 1053: 'stairs', 1054: 'below', 1055: 'achieved', 1056: 'removed', 1057: 'travellers', 1058: 'particular', 1059: 'overview', 1060: 'exhausted', 1061: 'lips', 1062: 'trembling', 1063: 'panic', 1064: 'stairway', 1065: 'besides', 1066: 'banister', 1067: 'believing', 1068: 'swayed', 1069: 'jumped', 1070: 'fingers', 1071: 'hurrying', 1072: 'jaws', 1073: 'screaming', 1074: 'run', 1075: 'self', 1076: 'overcoat', 1077: 'stamped', 1078: 'noises', 1079: 'choice', 1080: 'frequent', 1081: 'unbearable', 1082: 'confused', 1083: 'pleased', 1084: 'space', 1085: 'experience', 1086: 'regard', 1087: 'stuck', 1088: 'woken', 1089: 'afterwards', 1090: 'impression', 1091: 'leading', 1092: 'electric', 1093: 'badly', 1094: 'dragged', 1095: 'pieces', 1096: 'bread', 1097: 'disappointment', 1098: 'tender', 1099: 'worked', 1100: 'taste', 1101: 'crack', 1102: 'pride', 1103: 'frightening', 1104: 'shame', 1105: 'passed', 1106: 'frequently', 1107: 'led', 1108: 'opportunity', 1109: 'stranger', 1110: 'hungry', 1111: 'draw', 1112: 'splashed', 1113: 'vegetables', 1114: 'sauce', 1115: 'water', 1116: 'permanently', 1117: 'aside', 1118: 'placed', 1119: 'injuries', 1120: 'hurt', 1121: 'less', 1122: 'foods', 1123: 'suffocating', 1124: 'received', 1125: 'distress', 1126: 'comment', 1127: 'cleared', 1128: 'directly', 1129: 'rooms', 1130: 'meals', 1131: 'hour', 1132: 'receive', 1133: 'thanks', 1134: 'prospects', 1135: 'cash', 1136: 'collapsed', 1137: 'reduced', 1138: 'gratitude', 1139: 'unlike', 1140: 'plan', 1141: 'interrupted', 1142: 'explanations', 1143: 'keeping', 1144: 'unexpected', 1145: 'holiday', 1146: 'elderly', 1147: 'suffered', 1148: 'struggling', 1149: 'wearing', 1150: 'helping', 1151: 'leather', 1152: 'hot', 1153: 'lie', 1154: 'known', 1155: 'lived', 1156: 'grey', 1157: 'twice', 1158: 'tidied', 1159: 'burdensome', 1160: 'unpleasant', 1161: 'transformation', 1162: 'staring', 1163: 'threatened', 1164: 'arrangement', 1165: 'appreciated', 1166: 'somewhat', 1167: 'listened', 1168: 'closely', 1169: 'removing', 1170: 'helped', 1171: 'unless', 1172: 'heaviest', 1173: 'warnings', 1174: 'minutes', 1175: 'abandoned', 1176: 'months', 1177: 'age', 1178: 'refused', 1179: 'dissuade', 1180: 'poked', 1181: 'considerate', 1182: 'fro', 1183: 'worn', 1184: 'school', 1185: 'glass', 1186: 'watch', 1187: 'shall', 1188: 'spoken', 1189: 'various', 1190: 'bottles', 1191: 'confusion', 1192: 'fainted', 1193: 'disappear', 1194: 'neglected', 1195: 'laying', 1196: 'nightgown', 1197: 'walk', 1198: 'companions', 1199: 'collar', 1200: 'bank', 1201: 'forgot', 1202: 'shock', 1203: 'point', 1204: 'lodged', 1205: 'dared', 1206: 'injury', 1207: 'current', 1208: 'permission', 1209: 'hotel', 1210: 'shop', 1211: 'wake', 1212: 'sewing', 1213: 'exchange', 1214: 'peaceful', 1215: 'tug', 1216: 'ear', 1217: 'smaller', 1218: 'sold', 1219: 'strangers', 1220: 'cheek', 1221: 'whom', 1222: 'shown', 1223: 'indifferent', 1224: 'dirt', 1225: 'cleaning', 1226: 'alone', 1227: 'closing', 1228: 'amazement', 1229: 'crossed', 1230: 'failed', 1231: 'indicating', 1232: 'toward', 1233: 'prepared', 1234: 'spit', 1235: 'anywhere', 1236: 'lain', 1237: 'meat', 1238: 'bowed', 1239: 'throughout', 1240: 'love', 1241: 'begin', 1242: 'seat', 1243: 'everywhere', 1244: 'obvious', 1245: 'beautiful', 1246: 'expression', 1247: 'emotion', 1248: 'lap', 1249: 'beds', 1250: 'tenants', 1251: 'action', 1252: 'ahead', 1253: 'weak', 1254: 'brother', 1255: 'endure', 1256: 'certainty', 1257: 'vigorously', 1258: 'willing', 1259: 'glance', 1260: 'weaker', 1261: 'slamming', 1262: 'corpse', 1263: 'men', 1264: 'wife', 1265: 'irritation', 1266: 'tram', 1267: 'troubled', 1268: 'transformed', 1269: 'vermin', 1270: 'domed', 1271: 'divided', 1272: 'arches', 1273: 'sections', 1274: 'bedding', 1275: 'cover', 1276: 'slide', 1277: 'pitifully', 1278: 'compared', 1279: 'waved', 1280: 'helplessly', 1281: 'textile', 1282: 'illustrated', 1283: 'magazine', 1284: 'housed', 1285: 'gilded', 1286: 'boa', 1287: 'muff', 1288: 'viewer', 1289: 'nonsense', 1290: 'hundred', 1291: 'floundering', 1292: 'mild', 1293: 'strenuous', 1294: 'career', 1295: 'takes', 1296: 'connections', 1297: 'irregular', 1298: 'contact', 1299: 'hell', 1300: 'headboard', 1301: 'lots', 1302: 'spots', 1303: 'shudder', 1304: 'former', 1305: 'luxury', 1306: 'guest', 1307: 'copy', 1308: 'contract', 1309: 'kicked', 1310: 'knows', 1311: 'funny', 1312: 'subordinates', 1313: 'suppose', 1314: 'leaves', 1315: 'ticking', 1316: 'heaven', 1317: 'packed', 1318: 'spineless', 1319: 'reported', 1320: 'sick', 1321: 'strained', 1322: 'medical', 1323: 'insurance', 1324: 'lazy', 1325: 'accept', 1326: 'recommendation', 1327: 'claim', 1328: 'believed', 1329: 'workshy', 1330: 'case', 1331: 'excessive', 1332: 'sleepiness', 1333: 'thinking', 1334: 'decide', 1335: 'gentle', 1336: 'answering', 1337: 'recognised', 1338: 'uncontrollable', 1339: 'squeaking', 1340: 'echo', 1341: 'unclear', 1342: 'hearer', 1343: 'unsure', 1344: 'contented', 1345: 'satisfied', 1346: 'shuffled', 1347: 'expectations', 1348: 'warning', 1349: 'deepness', 1350: 'plaintively', 1351: 'strangeness', 1352: 'enunciating', 1353: 'pauses', 1354: 'congratulated', 1355: 'locking', 1356: 'awkwardly', 1357: 'pure', 1358: 'imagination', 1359: 'wondered', 1360: 'imaginings', 1361: 'resolve', 1362: 'doubt', 1363: 'occupational', 1364: 'hazard', 1365: 'exceptionally', 1366: 'continuously', 1367: 'leg', 1368: 'frenzy', 1369: 'carelessly', 1370: 'shoved', 1371: 'chose', 1372: 'bedpost', 1373: 'burning', 1374: 'breadth', 1375: 'bulk', 1376: 'lose', 1377: 'consciousness', 1378: 'sighing', 1379: 'struggled', 1380: 'chaos', 1381: 'rushing', 1382: 'desperate', 1383: 'enveloped', 1384: 'cheer', 1385: 'offer', 1386: 'stillness', 1387: 'natural', 1388: 'strikes', 1389: 'swinging', 1390: 'length', 1391: 'succeeded', 1392: 'injuring', 1393: 'bound', 1394: 'risked', 1395: 'sticking', 1396: 'method', 1397: 'game', 1398: 'rock', 1399: 'dome', 1400: 'peel', 1401: 'hopefully', 1402: 'suppress', 1403: 'balance', 1404: 'rocked', 1405: 'final', 1406: 'ring', 1407: 'danced', 1408: 'nonsensical', 1409: 'greeting', 1410: 'condemned', 1411: 'shortcoming', 1412: 'louts', 1413: 'faithful', 1414: 'devoted', 1415: 'pangs', 1416: 'conscience', 1417: 'trainees', 1418: 'assuming', 1419: 'trusted', 1420: 'wisdom', 1421: 'investigate', 1422: 'thump', 1423: 'softened', 1424: 'elastic', 1425: 'muffled', 1426: 'noticeable', 1427: 'concede', 1428: 'gruff', 1429: 'footsteps', 1430: 'adjoining', 1431: 'daring', 1432: 'personally', 1433: 'forgive', 1434: 'untidiness', 1435: 'missed', 1436: 'lad', 1437: 'thinks', 1438: 'cross', 1439: 'goes', 1440: 'sits', 1441: 'reads', 1442: 'studies', 1443: 'timetables', 1444: 'opens', 1445: 'thoughtfully', 1446: 'miss', 1447: 'commerce', 1448: 'considerations', 1449: 'impatiently', 1450: 'join', 1451: 'begun', 1452: 'losing', 1453: 'pursue', 1454: 'demands', 1455: 'minor', 1456: 'discourtesy', 1457: 'disturbing', 1458: 'barricade', 1459: 'mention', 1460: 'duties', 1461: 'request', 1462: 'peculiar', 1463: 'whims', 1464: 'suggest', 1465: 'entrusted', 1466: 'honour', 1467: 'incomprehensible', 1468: 'whatsoever', 1469: 'intercede', 1470: 'secure', 1471: 'originally', 1472: 'private', 1473: 'turnover', 1474: 'unsatisfactory', 1475: 'recognise', 1476: 'allow', 1477: 'excitement', 1478: 'dizziness', 1479: 'symptom', 1480: 'illness', 1481: 'basis', 1482: 'accusations', 1483: 'read', 1484: 'latest', 1485: 'contracts', 1486: 'recommend', 1487: 'gushed', 1488: 'practise', 1489: 'responsibility', 1490: 'station', 1491: 'smooth', 1492: 'nearby', 1493: 'edges', 1494: 'fools', 1495: 'communicated', 1496: 'calmness', 1497: 'screams', 1498: 'clapping', 1499: 'swishing', 1500: 'wrenching', 1501: 'banging', 1502: 'homes', 1503: 'awful', 1504: 'calmer', 1505: 'clearer', 1506: 'ears', 1507: 'response', 1508: 'confident', 1509: 'wise', 1510: 'among', 1511: 'achievements', 1512: 'distinguish', 1513: 'crucial', 1514: 'coughed', 1515: 'care', 1516: 'coughs', 1517: 'tips', 1518: 'recover', 1519: 'involved', 1520: 'fluid', 1521: 'dripped', 1522: 'greatly', 1523: 'encouraged', 1524: 'calling', 1525: 'paying', 1526: 'snapped', 1527: 'regained', 1528: 'exclaim', 1529: 'soughing', 1530: 'wind', 1531: 'nearest', 1532: 'retreating', 1533: 'invisible', 1534: 'dishevelled', 1535: 'breast', 1536: 'hostile', 1537: 'clenched', 1538: 'uncertainly', 1539: 'wept', 1540: 'powerful', 1541: 'peered', 1542: 'lighter', 1543: 'endless', 1544: 'building', 1545: 'austere', 1546: 'regular', 1547: 'facade', 1548: 'throwing', 1549: 'droplets', 1550: 'number', 1551: 'photograph', 1552: 'lieutenant', 1553: 'army', 1554: 'sword', 1555: 'carefree', 1556: 'bearing', 1557: 'pack', 1558: 'commercial', 1559: 'traveller', 1560: 'arduous', 1561: 'accurately', 1562: 'temporarily', 1563: 'diligence', 1564: 'trapped', 1565: 'likes', 1566: 'wage', 1567: 'soft', 1568: 'prejudice', 1569: 'staff', 1570: 'businessman', 1571: 'mistakes', 1572: 'harshly', 1573: 'victim', 1574: 'gossip', 1575: 'groundless', 1576: 'complaints', 1577: 'defend', 1578: 'arrive', 1579: 'trip', 1580: 'harmful', 1581: 'effects', 1582: 'protruding', 1583: 'stared', 1584: 'steadily', 1585: 'gradually', 1586: 'prohibition', 1587: 'supernatural', 1588: 'extreme', 1589: 'won', 1590: 'depended', 1591: 'clever', 1592: 'lover', 1593: 'considering', 1594: 'speech', 1595: 'reach', 1596: 'ridiculously', 1597: 'scream', 1598: 'sought', 1599: 'numerous', 1600: 'solid', 1601: 'sorrows', 1602: 'crouched', 1603: 'engrossed', 1604: 'shouting', 1605: 'pity', 1606: 'suggested', 1607: 'unthinking', 1608: 'seeming', 1609: 'pot', 1610: 'knocked', 1611: 'gush', 1612: 'pouring', 1613: 'snapping', 1614: 'flow', 1615: 'anew', 1616: 'chin', 1617: 'reaching', 1618: 'leapt', 1619: 'shouts', 1620: 'resounding', 1621: 'staircase', 1622: 'flight', 1623: 'controlled', 1624: 'impeding', 1625: 'seized', 1626: 'stamping', 1627: 'humbly', 1628: 'chilly', 1629: 'draught', 1630: 'curtains', 1631: 'fluttered', 1632: 'blown', 1633: 'drove', 1634: 'wild', 1635: 'practice', 1636: 'impatient', 1637: 'threat', 1638: 'lethal', 1639: 'disgust', 1640: 'incapable', 1641: 'anxious', 1642: 'glances', 1643: 'hinder', 1644: 'tip', 1645: 'mistake', 1646: 'occur', 1647: 'fixed', 1648: 'preparation', 1649: 'pleasant', 1650: 'angle', 1651: 'flank', 1652: 'scraped', 1653: 'vile', 1654: 'flecks', 1655: 'quivering', 1656: 'hefty', 1657: 'released', 1658: 'flying', 1659: 'bleeding', 1660: 'ii', 1661: 'awoke', 1662: 'lamps', 1663: 'shone', 1664: 'palely', 1665: 'tops', 1666: 'clumsily', 1667: 'antennae', 1668: 'beginning', 1669: 'value', 1670: 'scar', 1671: 'limped', 1672: 'rows', 1673: 'events', 1674: 'lifelessly', 1675: 'sweetened', 1676: 'floating', 1677: 'laughed', 1678: 'dipped', 1679: 'covering', 1680: 'snuffling', 1681: 'favourite', 1682: 'drink', 1683: 'centre', 1684: 'gas', 1685: 'lit', 1686: 'write', 1687: 'recent', 1688: 'lead', 1689: 'gazing', 1690: 'wealth', 1691: 'comfort', 1692: 'resolved', 1693: 'timorous', 1694: 'vain', 1695: 'previous', 1696: 'unlocked', 1697: 'keys', 1698: 'gaslight', 1699: 'awake', 1700: 'distinctly', 1701: 'plenty', 1702: 'undisturbed', 1703: 'tall', 1704: 'ease', 1705: 'underneath', 1706: 'vague', 1707: 'hopes', 1708: 'conclusion', 1709: 'patience', 1710: 'unpleasantness', 1711: 'impose', 1712: 'decisions', 1713: 'ended', 1714: 'flown', 1715: 'edge', 1716: 'terrible', 1717: 'rag', 1718: 'imagining', 1719: 'wildest', 1720: 'possibilities', 1721: 'guessed', 1722: 'goodness', 1723: 'selection', 1724: 'bones', 1725: 'raisins', 1726: 'almonds', 1727: 'declared', 1728: 'inedible', 1729: 'dry', 1730: 'roll', 1731: 'butter', 1732: 'salt', 1733: 'poured', 1734: 'feelings', 1735: 'whirred', 1736: 'healed', 1737: 'knife', 1738: 'yesterday', 1739: 'sucking', 1740: 'greedily', 1741: 'compellingly', 1742: 'attracted', 1743: 'watering', 1744: 'consumed', 1745: 'lethargic', 1746: 'withdraw', 1747: 'rounded', 1748: 'bulging', 1749: 'unselfconsciously', 1750: 'swept', 1751: 'mixing', 1752: 'dropped', 1753: 'bin', 1754: 'lid', 1755: 'second', 1756: 'errand', 1757: 'starve', 1758: 'feeding', 1759: 'suffering', 1760: 'content', 1761: 'sighs', 1762: 'saints', 1763: 'construed', 1764: 'enjoyed', 1765: 'diligently', 1766: 'sadly', 1767: 'scurry', 1768: 'appropriate', 1769: 'press', 1770: 'seldom', 1771: 'mealtime', 1772: 'subject', 1773: 'knees', 1774: 'begged', 1775: 'within', 1776: 'tearfully', 1777: 'thanking', 1778: 'dismissal', 1779: 'swore', 1780: 'emphatically', 1781: 'cooking', 1782: 'bother', 1783: 'unsuccessfully', 1784: 'similar', 1785: 'drank', 1786: 'beer', 1787: 'hoping', 1788: 'add', 1789: 'selfish', 1790: 'housekeeper', 1791: 'explained', 1792: 'finances', 1793: 'receipt', 1794: 'document', 1795: 'box', 1796: 'saved', 1797: 'complicated', 1798: 'item', 1799: 'incarcerated', 1800: 'arrange', 1801: 'fiery', 1802: 'vigour', 1803: 'junior', 1804: 'representative', 1805: 'overnight', 1806: 'ways', 1807: 'converted', 1808: 'benefit', 1809: 'delighted', 1810: 'splendour', 1811: 'costs', 1812: 'affection', 1813: 'return', 1814: 'gifted', 1815: 'expressive', 1816: 'violinist', 1817: 'expense', 1818: 'periods', 1819: 'mentioned', 1820: 'lovely', 1821: 'planned', 1822: 'grand', 1823: 'announcement', 1824: 'pointless', 1825: 'wearily', 1826: 'matters', 1827: 'misfortunes', 1828: 'available', 1829: 'meantime', 1830: 'accumulated', 1831: 'accumulating', 1832: 'enthusiasm', 1833: 'thrift', 1834: 'caution', 1835: 'surplus', 1836: 'reduce', 1837: 'freed', 1838: 'enable', 1839: 'maintain', 1840: 'emergencies', 1841: 'healthy', 1842: 'lacking', 1843: 'clumsy', 1844: 'asthma', 1845: 'seventeen', 1846: 'till', 1847: 'enviable', 1848: 'consisting', 1849: 'joining', 1850: 'modest', 1851: 'pleasures', 1852: 'cool', 1853: 'wink', 1854: 'scratching', 1855: 'climbing', 1856: 'sill', 1857: 'propped', 1858: 'leaning', 1859: 'stare', 1860: 'sense', 1861: 'freedom', 1862: 'distinct', 1863: 'charlottenstrasse', 1864: 'city', 1865: 'barren', 1866: 'sky', 1867: 'earth', 1868: 'mingled', 1869: 'inseparably', 1870: 'observant', 1871: 'exact', 1872: 'inner', 1873: 'thank', 1874: 'naturally', 1875: 'pretend', 1876: 'entered', 1877: 'sooner', 1878: 'precaution', 1879: 'shivering', 1880: 'ordeal', 1881: 'motionless', 1882: 'bite', 1883: 'hide', 1884: 'flee', 1885: 'protruded', 1886: 'bedsheet', 1887: 'arranged', 1888: 'glimpsed', 1889: 'fourteen', 1890: 'girl', 1891: 'useless', 1892: 'behaved', 1893: 'visit', 1894: 'persuaded', 1895: 'approved', 1896: 'unfortunate', 1897: 'courage', 1898: 'adult', 1899: 'appreciation', 1900: 'square', 1901: 'meters', 1902: 'entertain', 1903: 'freely', 1904: 'relaxed', 1905: 'happy', 1906: 'crash', 1907: 'traces', 1908: 'sixteen', 1909: 'bravely', 1910: 'cook', 1911: 'choose', 1912: 'approached', 1913: 'express', 1914: 'joy', 1915: 'folds', 1916: 'refrained', 1917: 'spying', 1918: 'pair', 1919: 'feeble', 1920: 'heaving', 1921: 'lasted', 1922: 'labouring', 1923: 'saddened', 1924: 'heart', 1925: 'whose', 1926: 'whereabouts', 1927: 'tone', 1928: 'added', 1929: 'wo', 1930: 'cope', 1931: 'comes', 1932: 'unchanged', 1933: 'communication', 1934: 'monotonous', 1935: 'emptied', 1936: 'transform', 1937: 'cave', 1938: 'inherited', 1939: 'unimpeded', 1940: 'shaken', 1941: 'influence', 1942: 'mindlessly', 1943: 'loss', 1944: 'advantage', 1945: 'agree', 1946: 'spokesman', 1947: 'concerned', 1948: 'advice', 1949: 'sufficient', 1950: 'childish', 1951: 'perversity', 1952: 'whereas', 1953: 'enthusiastic', 1954: 'tempted', 1955: 'dominated', 1956: 'groaning', 1957: 'pulling', 1958: 'inch', 1959: 'startlement', 1960: 'prevent', 1961: 'attract', 1962: 'assure', 1963: 'unusual', 1964: 'calls', 1965: 'scraping', 1966: 'assailed', 1967: 'emptying', 1968: 'dear', 1969: 'containing', 1970: 'tools', 1971: 'homework', 1972: 'trainee', 1973: 'infant', 1974: 'catching', 1975: 'sallied', 1976: 'denuded', 1977: 'copious', 1978: 'firmly', 1979: 'met', 1980: 'albeit', 1981: 'tremor', 1982: 'safe', 1983: 'unyielding', 1984: 'jump', 1985: 'patch', 1986: 'flowers', 1987: 'wallpaper', 1988: 'glowering', 1989: 'smelling', 1990: 'salts', 1991: 'faint', 1992: 'advise', 1993: 'bottle', 1994: 'splinter', 1995: 'caustic', 1996: 'medicine', 1997: 'delaying', 1998: 'oppressed', 1999: 'anxiety', 2000: 'spin', 2001: 'numb', 2002: 'subdued', 2003: 'openly', 2004: 'responsible', 2005: 'act', 2006: 'violence', 2007: 'subtleties', 2008: 'ah', 2009: 'sounding', 2010: 'angry', 2011: 'imagined', 2012: 'entombed', 2013: 'trips', 2014: 'armchair', 2015: 'sunday', 2016: 'public', 2017: 'wrapped', 2018: 'labour', 2019: 'walking', 2020: 'invariably', 2021: 'smart', 2022: 'blue', 2023: 'banking', 2024: 'institute', 2025: 'emerged', 2026: 'bushy', 2027: 'eyebrows', 2028: 'alert', 2029: 'unkempt', 2030: 'combed', 2031: 'scalp', 2032: 'monogram', 2033: 'arc', 2034: 'trouser', 2035: 'bottom', 2036: 'determination', 2037: 'walked', 2038: 'unusually', 2039: 'soles', 2040: 'wasted', 2041: 'strict', 2042: 'scurried', 2043: 'decisive', 2044: 'largely', 2045: 'feared', 2046: 'provoking', 2047: 'step', 2048: 'countless', 2049: 'noticeably', 2050: 'lungs', 2051: 'reliable', 2052: 'lurched', 2053: 'muster', 2054: 'saving', 2055: 'concealed', 2056: 'carved', 2057: 'notches', 2058: 'protrusions', 2059: 'tossed', 2060: 'bombard', 2061: 'fruit', 2062: 'bowl', 2063: 'sideboard', 2064: 'aim', 2065: 'red', 2066: 'apples', 2067: 'motors', 2068: 'glanced', 2069: 'harm', 2070: 'squarely', 2071: 'drag', 2072: 'incredible', 2073: 'changing', 2074: 'nailed', 2075: 'senses', 2076: 'blouse', 2077: 'unfastened', 2078: 'sliding', 2079: 'stumbling', 2080: 'uniting', 2081: 'ability', 2082: 'begging', 2083: 'iii', 2084: 'flesh', 2085: 'visible', 2086: 'reminder', 2087: 'revolting', 2088: 'form', 2089: 'member', 2090: 'treated', 2091: 'enemy', 2092: 'duty', 2093: 'swallow', 2094: 'revulsion', 2095: 'mobility', 2096: 'ancient', 2097: 'invalid', 2098: 'deterioration', 2099: 'opinion', 2100: 'thus', 2101: 'differently', 2102: 'conversations', 2103: 'ones', 2104: 'longing', 2105: 'damp', 2106: 'nowadays', 2107: 'lamp', 2108: 'sew', 2109: 'fancy', 2110: 'underwear', 2111: 'fashion', 2112: 'sales', 2113: 'shorthand', 2114: 'french', 2115: 'dozing', 2116: 'grin', 2117: 'unused', 2118: 'peg', 2119: 'slumber', 2120: 'serve', 2121: 'expecting', 2122: 'superior', 2123: 'result', 2124: 'shabbier', 2125: 'stains', 2126: 'shiny', 2127: 'uncomfortable', 2128: 'obstinate', 2129: 'regularly', 2130: 'importune', 2131: 'reproaches', 2132: 'refusing', 2133: 'sleeve', 2134: 'whisper', 2135: 'endearments', 2136: 'effect', 2137: 'sink', 2138: 'deeper', 2139: 'abruptly', 2140: 'supported', 2141: 'needle', 2142: 'pen', 2143: 'overworked', 2144: 'household', 2145: 'budget', 2146: 'dismissed', 2147: 'flapped', 2148: 'amount', 2149: 'hoped', 2150: 'items', 2151: 'jewellery', 2152: 'belonging', 2153: 'functions', 2154: 'celebrations', 2155: 'loudest', 2156: 'complaint', 2157: 'imaginable', 2158: 'transferring', 2159: 'address', 2160: 'reasons', 2161: 'transport', 2162: 'crate', 2163: 'holes', 2164: 'related', 2165: 'world', 2166: 'expects', 2167: 'poor', 2168: 'sacrificed', 2169: 'behest', 2170: 'customers', 2171: 'mingle', 2172: 'affairs', 2173: 'apprentices', 2174: 'teaboy', 2175: 'businesses', 2176: 'chambermaids', 2177: 'provincial', 2178: 'memory', 2179: 'cashier', 2180: 'inaccessible', 2181: 'rage', 2182: 'plans', 2183: 'pantry', 2184: 'entitled', 2185: 'sweep', 2186: 'untouched', 2187: 'quicker', 2188: 'smears', 2189: 'balls', 2190: 'filth', 2191: 'worst', 2192: 'places', 2193: 'reproach', 2194: 'weeks', 2195: 'touchy', 2196: 'thoroughly', 2197: 'bucketfuls', 2198: 'dampness', 2199: 'bitter', 2200: 'punished', 2201: 'aggrieved', 2202: 'mothers', 2203: 'imploring', 2204: 'convulsive', 2205: 'helpless', 2206: 'agitated', 2207: 'accused', 2208: 'quaking', 2209: 'thumped', 2210: 'hissed', 2211: 'widow', 2212: 'robust', 2213: 'bone', 2214: 'structure', 2215: 'withstand', 2216: 'hardest', 2217: 'repelled', 2218: 'curiosity', 2219: 'chasing', 2220: 'considered', 2221: 'responded', 2222: 'disturb', 2223: 'windowpanes', 2224: 'spring', 2225: 'resentful', 2226: 'infirm', 2227: 'intending', 2228: 'changes', 2229: 'earnest', 2230: 'peering', 2231: 'tidy', 2232: 'establishment', 2233: 'clutter', 2234: 'tolerate', 2235: 'dirty', 2236: 'furnishings', 2237: 'equipment', 2238: 'superfluous', 2239: 'discard', 2240: 'dustbins', 2241: 'chuck', 2242: 'object', 2243: 'woman', 2244: 'likely', 2245: 'junk', 2246: 'enjoy', 2247: 'darkest', 2248: 'formerly', 2249: 'serviettes', 2250: 'knives', 2251: 'forks', 2252: 'piled', 2253: 'potatoes', 2254: 'steaming', 2255: 'dishes', 2256: 'count', 2257: 'authority', 2258: 'piece', 2259: 'wishing', 2260: 'establish', 2261: 'sufficiently', 2262: 'cooked', 2263: 'satisfaction', 2264: 'mumbled', 2265: 'perfect', 2266: 'remarkable', 2267: 'chewing', 2268: 'perform', 2269: 'toothless', 2270: 'feed', 2271: 'dying', 2272: 'produced', 2273: 'page', 2274: 'smoking', 2275: 'attentive', 2276: 'cosy', 2277: 'player', 2278: 'therefore', 2279: 'exaggerated', 2280: 'courtesy', 2281: 'offered', 2282: 'paid', 2283: 'thoughtless', 2284: 'hidden', 2285: 'threads', 2286: 'hairs', 2287: 'remains', 2288: 'wipe', 2289: 'shy', 2290: 'immaculate', 2291: 'preoccupied', 2292: 'notes', 2293: 'withdrew', 2294: 'heads', 2295: 'sunk', 2296: 'volume', 2297: 'observed', 2298: 'disappointed', 2299: 'performance', 2300: 'politeness', 2301: 'unnerving', 2302: 'blew', 2303: 'smoke', 2304: 'cigarettes', 2305: 'upwards', 2306: 'noses', 2307: 'beautifully', 2308: 'lines', 2309: 'melancholy', 2310: 'meet', 2311: 'captivate', 2312: 'unknown', 2313: 'nourishment', 2314: 'yearning', 2315: 'determined', 2316: 'skirt', 2317: 'hiss', 2318: 'attackers', 2319: 'refuse', 2320: 'shoulder', 2321: 'kiss', 2322: 'necklace', 2323: 'mr', 2324: 'pointing', 2325: 'wasting', 2326: 'forefinger', 2327: 'driving', 2328: 'attempted', 2329: 'block', 2330: 'dawning', 2331: 'realisation', 2332: 'neighbour', 2333: 'tugged', 2334: 'drop', 2335: 'bow', 2336: 'hang', 2337: 'limply', 2338: 'instrument', 2339: 'laboriously', 2340: 'pressure', 2341: 'pillows', 2342: 'slipped', 2343: 'obsessed', 2344: 'owed', 2345: 'urged', 2346: 'thunder', 2347: 'thereby', 2348: 'halt', 2349: 'declare', 2350: 'glancing', 2351: 'gain', 2352: 'repugnant', 2353: 'conditions', 2354: 'prevail', 2355: 'decisively', 2356: 'proceed', 2357: 'damages', 2358: 'grounds', 2359: 'joined', 2360: 'staggered', 2361: 'stretching', 2362: 'nap', 2363: 'uncontrolled', 2364: 'nodding', 2365: 'introduction', 2366: 'monster', 2367: 'humanly', 2368: 'cough', 2369: 'dully', 2370: 'deranged', 2371: 'forehead', 2372: 'definite', 2373: 'ideas', 2374: 'plates', 2375: 'occasionally', 2376: 'coughing', 2377: 'tortured', 2378: 'wiped', 2379: 'mechanical', 2380: 'sympathy', 2381: 'shrugged', 2382: 'helplessness', 2383: 'displacing', 2384: 'acceptance', 2385: 'harmed', 2386: 'beings', 2387: 'lives', 2388: 'persecuting', 2389: 'streets', 2390: 'starting', 2391: 'beyond', 2392: 'comprehension', 2393: 'excited', 2394: 'protect', 2395: 'startling', 2396: 'required', 2397: 'deal', 2398: 'repeatedly', 2399: 'striking', 2400: 'alarmed', 2401: 'unhappy', 2402: 'exhaustion', 2403: 'panting', 2404: 'separated', 2405: 'noticing', 2406: 'concentrated', 2407: 'distract', 2408: 'sprung', 2409: 'discovery', 2410: 'spindly', 2411: 'unnatural', 2412: 'aching', 2413: 'altogether', 2414: 'decayed', 2415: 'inflamed', 2416: 'area', 2417: 'strongly', 2418: 'rumination', 2419: 'tower', 2420: 'strike', 2421: 'weakly', 2422: 'nostrils', 2423: 'brief', 2424: 'special', 2425: 'purpose', 2426: 'martyr', 2427: 'attributed', 2428: 'tickle', 2429: 'nuisance', 2430: 'resistance', 2431: 'whistled', 2432: 'yank', 2433: 'shout', 2434: 'bedrooms', 2435: 'stone', 2436: 'marriage', 2437: 'blanket', 2438: 'nightdress', 2439: 'paleness', 2440: 'confirm', 2441: 'enquiringly', 2442: 'checked', 2443: 'checking', 2444: 'replied', 2445: 'prove', 2446: 'sending', 2447: 'sideways', 2448: 'complete', 2449: 'example', 2450: 'dried', 2451: 'pained', 2452: 'warmth', 2453: 'march', 2454: 'irritably', 2455: 'coats', 2456: 'disconcerted', 2457: 'sweetly', 2458: 'backs', 2459: 'continually', 2460: 'gleeful', 2461: 'anticipation', 2462: 'quarrel', 2463: 'favour', 2464: 'contents', 2465: 'rearranging', 2466: 'positions', 2467: 'humility', 2468: 'strides', 2469: 'rubbing', 2470: 'friend', 2471: 'fear', 2472: 'connection', 2473: 'leader', 2474: 'hats', 2475: 'sticks', 2476: 'holder', 2477: 'premises', 2478: 'mistrust', 2479: 'leaned', 2480: 'progress', 2481: 'reappear', 2482: 'moments', 2483: 'butcher', 2484: 'boy', 2485: 'proud', 2486: 'posture', 2487: 'tray', 2488: 'nearer', 2489: 'relieved', 2490: 'wrote', 2491: 'excusal', 2492: 'employers', 2493: 'contractor', 2494: 'principal', 2495: 'tremendous', 2496: 'vertical', 2497: 'ostrich', 2498: 'feather', 2499: 'source', 2500: 'laugh', 2501: 'sorted', 2502: 'intent', 2503: 'continuing', 2504: 'describing', 2505: 'detail', 2506: 'prevented', 2507: 'telling', 2508: 'peeved', 2509: 'cheerio', 2510: 'sharply', 2511: 'terribly', 2512: 'tonight', 2513: 'gets', 2514: 'destroyed', 2515: 'gained', 2516: 'twisted', 2517: 'stuff', 2518: 'kissed', 2519: 'hugged', 2520: 'country', 2521: 'sunshine', 2522: 'comfortably', 2523: 'seats', 2524: 'discussed', 2525: 'examination', 2526: 'jobs', 2527: 'promise', 2528: 'cheaper', 2529: 'location', 2530: 'practical', 2531: 'livelier', 2532: 'cheeks', 2533: 'pale', 2534: 'simultaneously', 2535: 'blossoming', 2536: 'built', 2537: 'quieter', 2538: 'agreed', 2539: 'confirmation', 2540: 'destination'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-fhffAQcxJe5","executionInfo":{"status":"ok","timestamp":1623399112629,"user_tz":-330,"elapsed":1166,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"36930b79-a0ec-41f5-f82b-000e3da76e7b"},"source":["from keras.utils.np_utils import to_categorical\n","target_data=to_categorical(target_data,vocab_size)\n","print(target_data[:3,:])\n","print(target_data.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","(21927, 2541)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DPGODcuD_vPT"},"source":["*Google's Word2Vec*"]},{"cell_type":"code","metadata":{"id":"HSmjZcbWl_3g"},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# # Google's Word2Vec\n","# word2vec = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/GoogleNews-vectors-negative300.bin', binary=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1_jT3Eeh_3cz"},"source":["*Stanford's Word2Vec: GloVe*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GPytlp9_ur_","executionInfo":{"status":"ok","timestamp":1623399302365,"user_tz":-330,"elapsed":188541,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"c0daff51-bc0e-4e8f-988b-0a96c07eb5b0"},"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip '/content/glove.6B.zip' "],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-06-11 08:11:53--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2021-06-11 08:11:53--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2021-06-11 08:11:54--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: glove.6B.zip\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.21MB/s    in 2m 42s  \n","\n","2021-06-11 08:14:35 (5.09 MB/s) - glove.6B.zip saved [862182613/862182613]\n","\n","Archive:  /content/glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pSsnw1-ACjE","executionInfo":{"status":"ok","timestamp":1623399308397,"user_tz":-330,"elapsed":6049,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"e74e96c9-3206-4118-96c0-f9b1c61e834f"},"source":["# store GloVe in word2vec format\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","#using 50d embeddings\n","glove_input_file = 'glove.6B.50d.txt'\n","word2vec_output_file = 'glove.6B.50d.txt.word2vec'\n","glove2word2vec(glove_input_file, word2vec_output_file)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(400000, 50)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"VnuXX4ZIAHbJ"},"source":["from gensim.models import KeyedVectors\n","filename = 'glove.6B.50d.txt.word2vec'\n","word2vec = KeyedVectors.load_word2vec_format(filename, binary=False) #binary tells about existing format"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GKbcVptFoQ9-","executionInfo":{"status":"ok","timestamp":1623399332910,"user_tz":-330,"elapsed":32,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"6c851aae-7ee4-47ec-9687-78f33ec4f75c"},"source":["n_words = len(tokenizer.word_index)+1\n","emb_dim=50 # based on glove dimension\n","emb_matrix = np.zeros((n_words,emb_dim))\n","emb_matrix.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2541, 50)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dr-4SSZeoUG9","executionInfo":{"status":"ok","timestamp":1623399332912,"user_tz":-330,"elapsed":30,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"b8c20dca-8c20-462c-9c6c-eb8cd2c67945"},"source":["for word,i in tokenizer.word_index.items():\n","  if word in word2vec.vocab:\n","    emb_matrix[i] = word2vec.word_vec(word)\n","emb_matrix.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2541, 50)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2GRsWt0rnH9","executionInfo":{"status":"ok","timestamp":1623399332913,"user_tz":-330,"elapsed":26,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"32f56faf-ab57-45e6-e508-be36c2689d94"},"source":["# create training and testing dataset\n","val_split=0.2\n","perm = np.random.permutation(len(data))\n","idx_train=perm[:int((len(data))*(1-val_split))]\n","idx_val=perm[int((len(data))*(1-val_split)):]\n","\n","train_words = data[idx_train]\n","train_target = target_data[idx_train]\n","val_set = data[idx_val]\n","val_target = target_data[idx_val]\n","print(train_words.shape, train_target.shape)\n","print(val_set.shape,val_target.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(17541, 4) (17541, 2541)\n","(4386, 4) (4386, 2541)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EQEzPBFxHkW6"},"source":["Step:<br>\n","1. Create model architecture in TensorFlow using Keras\n","2. Compile the model\n","3. Make necessary callback functions\n","4. Train model_1\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FU1jJfIhx8op","executionInfo":{"status":"ok","timestamp":1623401370577,"user_tz":-330,"elapsed":4652,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"1aaf1ba0-5f10-43ea-d05e-0f94a4fa0da2"},"source":["model_1=Sequential()\n","model_1.add(Embedding(vocab_size,35, input_length=train_size-pred_size))\n","model_1.add(Bidirectional(LSTM(1000,return_sequences=True)))\n","model_1.add(Bidirectional(LSTM(1000)))\n","model_1.add(Dense(1000,activation=\"relu\"))\n","model_1.add(Dense(vocab_size,activation=\"softmax\"))\n","\n","model_1.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 4, 35)             88935     \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 4, 2000)           8288000   \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 2000)              24008000  \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1000)              2001000   \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 2541)              2543541   \n","=================================================================\n","Total params: 36,929,476\n","Trainable params: 36,929,476\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cXpuIwbWyaHx"},"source":["# checkpoint=ModelCheckpoint(\"nextword_model_1.h5\",monitor=\"loss\",verbose=1,save_best_only=True,mode=\"auto\")\n","# reduce=ReduceLROnPlateau(monitor=\"loss\",factor=0.2,patience=3,min_lr=0.0001,verbose=1)\n","# earlystop=EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\",verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLtX4sMcykty","executionInfo":{"status":"ok","timestamp":1623401897312,"user_tz":-330,"elapsed":508379,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"fcd4bcc3-fe4e-4f34-cf60-49fc2c441ac9"},"source":["model_1.compile(loss=\"categorical_crossentropy\",optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n","history_1 = model_1.fit(train_words,train_target,epochs=25,batch_size=64) #,callbacks=[checkpoint,reduce,earlystop])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","275/275 [==============================] - 26s 73ms/step - loss: 6.1349 - accuracy: 0.0532\n","Epoch 2/25\n","275/275 [==============================] - 20s 73ms/step - loss: 5.5761 - accuracy: 0.0803\n","Epoch 3/25\n","275/275 [==============================] - 20s 72ms/step - loss: 5.1962 - accuracy: 0.1079\n","Epoch 4/25\n","275/275 [==============================] - 20s 73ms/step - loss: 4.8726 - accuracy: 0.1292\n","Epoch 5/25\n","275/275 [==============================] - 20s 73ms/step - loss: 4.6021 - accuracy: 0.1421\n","Epoch 6/25\n","275/275 [==============================] - 20s 73ms/step - loss: 4.3450 - accuracy: 0.1592\n","Epoch 7/25\n","275/275 [==============================] - 20s 72ms/step - loss: 4.0698 - accuracy: 0.1775\n","Epoch 8/25\n","275/275 [==============================] - 20s 73ms/step - loss: 3.7550 - accuracy: 0.2025\n","Epoch 9/25\n","275/275 [==============================] - 20s 73ms/step - loss: 3.3768 - accuracy: 0.2430\n","Epoch 10/25\n","275/275 [==============================] - 20s 73ms/step - loss: 2.9264 - accuracy: 0.3036\n","Epoch 11/25\n","275/275 [==============================] - 20s 73ms/step - loss: 2.4247 - accuracy: 0.3909\n","Epoch 12/25\n","275/275 [==============================] - 20s 73ms/step - loss: 1.8731 - accuracy: 0.5037\n","Epoch 13/25\n","275/275 [==============================] - 20s 72ms/step - loss: 1.3506 - accuracy: 0.6276\n","Epoch 14/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.8871 - accuracy: 0.7502\n","Epoch 15/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.5315 - accuracy: 0.8513\n","Epoch 16/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.3496 - accuracy: 0.9033\n","Epoch 17/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.1726 - accuracy: 0.9543\n","Epoch 18/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.1058 - accuracy: 0.9758\n","Epoch 19/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.0739 - accuracy: 0.9851\n","Epoch 20/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.0893 - accuracy: 0.9793\n","Epoch 21/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.0883 - accuracy: 0.9781\n","Epoch 22/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.1116 - accuracy: 0.9724\n","Epoch 23/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.1103 - accuracy: 0.9715\n","Epoch 24/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.1058 - accuracy: 0.9738\n","Epoch 25/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.1048 - accuracy: 0.9722\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1kZagaV7ICnj"},"source":["Step:<br>\n","1. Fetch the predictions of model_1 on train_words to create dataset for model_2"]},{"cell_type":"markdown","metadata":{"id":"ciw7fhNjY48s"},"source":["**BOOSTING**"]},{"cell_type":"code","metadata":{"id":"ZdEcJw_3jqz2"},"source":["pred_1 = model_1.predict(train_words)\n","fetch_pred_1=[]\n","for i in range(pred_1.shape[0]):\n","  word_i=np.argmax(pred_1[i])\n","  fetch_pred_1.append(word_i) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S1hs4AgmjuUe"},"source":["**Dataset model_2**"]},{"cell_type":"code","metadata":{"id":"nZ8NctnRqAi5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623401909987,"user_tz":-330,"elapsed":16,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"cc87cb1b-e606-424b-b3b2-81e2a3956d23"},"source":["# replacing target words with predictions of model_1\n","train_target = to_categorical(fetch_pred_1,vocab_size)\n","print(train_target[1])\n","print(train_target.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0. 0. 0. ... 0. 0. 0.]\n","(17541, 2541)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"thHLfkeQI9XL"},"source":["Step:<br>\n","1. Re-initialize the callbacks for model_2\n","2. Clone model_1 to get model_2 as they have same architecture\n","3. Compile and train model_2"]},{"cell_type":"code","metadata":{"id":"7yPKjXLIBS7K"},"source":["# checkpoint=ModelCheckpoint(\"nextword_model_2.h5\",monitor=\"loss\",verbose=1,save_best_only=True,mode=\"auto\")\n","# reduce=ReduceLROnPlateau(monitor=\"loss\",factor=0.2,patience=3,min_lr=0.0001,verbose=1)\n","# earlystop=EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\",verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59N6poiEw7Jx","executionInfo":{"status":"ok","timestamp":1623402421718,"user_tz":-330,"elapsed":511736,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"4c7db51a-daf9-4c49-df7a-ccf6d0979a8d"},"source":["model_2=clone_model(model_1)\n","model_2.compile(loss=\"categorical_crossentropy\",optimizer=Adam(lr=0.001),metrics=['accuracy'])\n","history_2=model_2.fit(train_words,train_target,epochs=25,batch_size=64) #callbacks=[checkpoint,reduce,earlystop])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/25\n","275/275 [==============================] - 26s 72ms/step - loss: 6.2139 - accuracy: 0.0421\n","Epoch 2/25\n","275/275 [==============================] - 20s 73ms/step - loss: 5.7013 - accuracy: 0.0664\n","Epoch 3/25\n","275/275 [==============================] - 20s 72ms/step - loss: 5.3148 - accuracy: 0.0990\n","Epoch 4/25\n","275/275 [==============================] - 20s 73ms/step - loss: 4.9554 - accuracy: 0.1231\n","Epoch 5/25\n","275/275 [==============================] - 20s 72ms/step - loss: 4.6637 - accuracy: 0.1349\n","Epoch 6/25\n","275/275 [==============================] - 20s 72ms/step - loss: 4.3968 - accuracy: 0.1543\n","Epoch 7/25\n","275/275 [==============================] - 20s 72ms/step - loss: 4.1207 - accuracy: 0.1694\n","Epoch 8/25\n","275/275 [==============================] - 20s 72ms/step - loss: 3.8108 - accuracy: 0.1921\n","Epoch 9/25\n","275/275 [==============================] - 20s 72ms/step - loss: 3.4471 - accuracy: 0.2322\n","Epoch 10/25\n","275/275 [==============================] - 20s 73ms/step - loss: 3.0129 - accuracy: 0.2909\n","Epoch 11/25\n","275/275 [==============================] - 20s 72ms/step - loss: 2.5168 - accuracy: 0.3813\n","Epoch 12/25\n","275/275 [==============================] - 20s 73ms/step - loss: 1.9558 - accuracy: 0.4922\n","Epoch 13/25\n","275/275 [==============================] - 20s 73ms/step - loss: 1.4206 - accuracy: 0.6154\n","Epoch 14/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.9130 - accuracy: 0.7444\n","Epoch 15/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.5278 - accuracy: 0.8493\n","Epoch 16/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.3465 - accuracy: 0.9046\n","Epoch 17/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.1791 - accuracy: 0.9543\n","Epoch 18/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.1377 - accuracy: 0.9657\n","Epoch 19/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.0752 - accuracy: 0.9842\n","Epoch 20/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.0566 - accuracy: 0.9886\n","Epoch 21/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.0397 - accuracy: 0.9925\n","Epoch 22/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.0523 - accuracy: 0.9900\n","Epoch 23/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.0977 - accuracy: 0.9754\n","Epoch 24/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.1893 - accuracy: 0.9474\n","Epoch 25/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.2056 - accuracy: 0.9412\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w-6EDeV1KTqO"},"source":["**???** *It can be seen that now the training accuracy has reduced than model_1 which is expected because now we have not used the original dataset for training but a dataset we created using predictions of model_1.*"]},{"cell_type":"markdown","metadata":{"id":"QhPdSbpSJRxU"},"source":["Step:<br>\n","1. Get predictions of model_2 on train_words to create model_3 dataset"]},{"cell_type":"code","metadata":{"id":"oq0K4E6o78YV"},"source":["pred_2 = model_2.predict(train_words)\n","fetch_pred_2=[]\n","for i in range(pred_2.shape[0]):\n","  word_i=np.argmax(pred_2[i])\n","  fetch_pred_2.append(word_i) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CMKKeTzG7trr"},"source":["**Dataset model_3**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mK6Oq_Q5EU5J","executionInfo":{"status":"ok","timestamp":1623402434447,"user_tz":-330,"elapsed":21,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"ed3e183a-1210-4872-9e2c-3dfef0b25340"},"source":["# replacing target words with predictions of model_1\n","train_target = to_categorical(fetch_pred_2,vocab_size)\n","print(train_target[1])\n","print(train_target.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0. 0. 0. ... 0. 0. 0.]\n","(17541, 2541)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6MutYfXqKFlr"},"source":["Step:<br>\n","1. Re-initialize call backs for model_3\n","2. Clone model_1 to get model_3\n","3. Compile and train model_3"]},{"cell_type":"code","metadata":{"id":"BnfX0YCQB6D9"},"source":["# checkpoint=ModelCheckpoint(\"nextword_model_3.h5\",monitor=\"loss\",verbose=1,save_best_only=True,mode=\"auto\")\n","# reduce=ReduceLROnPlateau(monitor=\"loss\",factor=0.2,patience=3,min_lr=0.0001,verbose=1)\n","# earlystop=EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\",verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BAtesgfx8nRF","executionInfo":{"status":"ok","timestamp":1623402942445,"user_tz":-330,"elapsed":508005,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"8626378d-0547-4d65-baaf-02c22b9718f5"},"source":["model_3=clone_model(model_1)\n","model_3.compile(loss=\"categorical_crossentropy\",optimizer=Adam(lr=0.001),metrics=['accuracy'])\n","history_3=model_3.fit(train_words,train_target,epochs=25,batch_size=64) #callbacks=[checkpoint,reduce,earlystop])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/25\n","275/275 [==============================] - 26s 72ms/step - loss: 6.2080 - accuracy: 0.0452\n","Epoch 2/25\n","275/275 [==============================] - 20s 72ms/step - loss: 5.6873 - accuracy: 0.0655\n","Epoch 3/25\n","275/275 [==============================] - 20s 73ms/step - loss: 5.3260 - accuracy: 0.1014\n","Epoch 4/25\n","275/275 [==============================] - 20s 73ms/step - loss: 4.9774 - accuracy: 0.1211\n","Epoch 5/25\n","275/275 [==============================] - 20s 73ms/step - loss: 4.6951 - accuracy: 0.1341\n","Epoch 6/25\n","275/275 [==============================] - 20s 73ms/step - loss: 4.4194 - accuracy: 0.1516\n","Epoch 7/25\n","275/275 [==============================] - 20s 73ms/step - loss: 4.1359 - accuracy: 0.1700\n","Epoch 8/25\n","275/275 [==============================] - 20s 72ms/step - loss: 3.8106 - accuracy: 0.1947\n","Epoch 9/25\n","275/275 [==============================] - 20s 72ms/step - loss: 3.4245 - accuracy: 0.2377\n","Epoch 10/25\n","275/275 [==============================] - 20s 72ms/step - loss: 2.9776 - accuracy: 0.2978\n","Epoch 11/25\n","275/275 [==============================] - 20s 72ms/step - loss: 2.4536 - accuracy: 0.3905\n","Epoch 12/25\n","275/275 [==============================] - 20s 72ms/step - loss: 1.9104 - accuracy: 0.5029\n","Epoch 13/25\n","275/275 [==============================] - 20s 72ms/step - loss: 1.3478 - accuracy: 0.6327\n","Epoch 14/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.8695 - accuracy: 0.7552\n","Epoch 15/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.5099 - accuracy: 0.8542\n","Epoch 16/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.2514 - accuracy: 0.9346\n","Epoch 17/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.1597 - accuracy: 0.9609\n","Epoch 18/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.0954 - accuracy: 0.9792\n","Epoch 19/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.0728 - accuracy: 0.9842\n","Epoch 20/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.0776 - accuracy: 0.9828\n","Epoch 21/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.1213 - accuracy: 0.9693\n","Epoch 22/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.2037 - accuracy: 0.9435\n","Epoch 23/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.0950 - accuracy: 0.9763\n","Epoch 24/25\n","275/275 [==============================] - 20s 73ms/step - loss: 0.0539 - accuracy: 0.9894\n","Epoch 25/25\n","275/275 [==============================] - 20s 72ms/step - loss: 0.0875 - accuracy: 0.9768\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JNI5P2yRgu7r"},"source":["**Prediction**"]},{"cell_type":"markdown","metadata":{"id":"8ZybAYHvKuYC"},"source":["Step:<br>\n","1. The input words are padded before running the model because may have a different size than 4"]},{"cell_type":"markdown","metadata":{"id":"GKHIbP1DBsmt"},"source":["**Multiple Words Prediction**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"je4cmGJkHWQj","executionInfo":{"status":"ok","timestamp":1623402942447,"user_tz":-330,"elapsed":38,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"6df64540-e215-4b25-b5d0-596c0ffd3577"},"source":["val_data = []\n","for w in val_set:\n","  val_data.extend(w)\n","print(len(val_data))\n","print(val_data[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["17544\n","[39, 1295, 85, 52, 21, 41, 4, 28, 374, 686]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CpA25j2eH4T3","executionInfo":{"status":"ok","timestamp":1623402942447,"user_tz":-330,"elapsed":30,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"3811472b-0735-4d79-ed1e-5f33aac82fd7"},"source":["size=4\n","pred=3\n","val_words=[]\n","target_val=[]\n","for i in range(size,len(val_data)):\n","  w = val_data[i-size:i]\n","  t = val_data[i:i+pred]\n","  val_words.append(w)\n","  target_val.append(t)\n","print(len(val_words), len(target_val))\n","print(val_words[:2])\n","print(target_val[:2])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["17540 17540\n","[[39, 1295, 85, 52], [1295, 85, 52, 21]]\n","[[21, 41, 4], [41, 4, 28]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"twxKL-_5NOmH","executionInfo":{"status":"ok","timestamp":1623402942448,"user_tz":-330,"elapsed":28,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"a79d01ed-f9a1-41ef-861b-7a2bdc8500ac"},"source":["X=np.asarray(val_words)\n","y=np.asarray(target_val)\n","print(X.shape, y.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(17540, 4) (17540,)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZBBmYELAJqfI"},"source":["# first word prediction stored in pred_1\n","pred = model_1.predict(X)\n","pred_1 = []\n","for i in range(pred.shape[0]):\n","  pred_1.append(np.argmax(pred[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DR9_k_ofP-Tb","executionInfo":{"status":"ok","timestamp":1623402963319,"user_tz":-330,"elapsed":21,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"50fa7031-7021-4c4c-ed94-67f4cca39418"},"source":["for i in range(len(val_words)):\n","  val_words[i].append(pred_1[i])\n","X = np.asarray(val_words)\n","X = pad_sequences(X, maxlen=4)\n","X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17540, 4)"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"6FrxKTPwWHzJ"},"source":["# second word prediction in pred_2\n","pred = model_2.predict(X)\n","pred_2 = []\n","for i in range(pred.shape[0]):\n","  pred_2.append(np.argmax(pred[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FIZUx0wEWRD3","executionInfo":{"status":"ok","timestamp":1623402985306,"user_tz":-330,"elapsed":19,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"131e21de-2be0-4b8f-ddb1-60f798d26e67"},"source":["for i in range(len(val_words)):\n","  val_words[i].append(pred_2[i])\n","X = np.asarray(val_words)\n","X = pad_sequences(X, maxlen=4)\n","X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17540, 4)"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"code","metadata":{"id":"fqF7ep3AXwLy"},"source":["# third word prediction in pred_3\n","pred = model_3.predict(X)\n","pred_3 = []\n","for i in range(pred.shape[0]):\n","  pred_3.append(np.argmax(pred[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T3I5BGlGfIOP"},"source":["**BAGGING**<br>\n","Trained model_1, model_2, model_3 on same dataset without replacement<br>\n","**Prediction**"]},{"cell_type":"code","metadata":{"id":"O9Qu-17fgIDK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623403107614,"user_tz":-330,"elapsed":643,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"fc47b7f1-330e-4213-9e56-aefbc948a274"},"source":["val_data = []\n","for w in val_set:\n","  val_data.extend(w)\n","print(len(val_data))\n","print(val_data[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["17544\n","[39, 1295, 85, 52, 21, 41, 4, 28, 374, 686]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wGiYMz3_gPDo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623403113567,"user_tz":-330,"elapsed":691,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"4c4e22ec-3ec0-470d-86ae-fe80aecb8030"},"source":["size=4\n","pred=3\n","val_words=[]\n","target_val=[]\n","for i in range(size,len(val_data)):\n","  w = val_data[i-size:i]\n","  t = val_data[i:i+pred]\n","  val_words.append(w)\n","  target_val.append(t)\n","print(len(val_words), len(target_val))\n","print(val_words[:2])\n","print(target_val[:2])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["17540 17540\n","[[39, 1295, 85, 52], [1295, 85, 52, 21]]\n","[[21, 41, 4], [41, 4, 28]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N9vvyloHgSv9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623403115880,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"b987f88d-27bb-475c-b16b-bd177c11c72d"},"source":["X=np.asarray(val_words)\n","y=np.asarray(target_val)\n","print(X.shape, y.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(17540, 4) (17540,)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xwGhJbiygXvX"},"source":["# first word prediction stored in pred_1\n","pred = model_1.predict(X)\n","pred_1 = []\n","for i in range(pred.shape[0]):\n","  pred_1.append(np.argmax(pred[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L7Zs9sWBgcgX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623403131951,"user_tz":-330,"elapsed":466,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"55677aff-4947-4f83-c94a-1dc561a49972"},"source":["for i in range(len(val_words)):\n","  val_words[i].append(pred_1[i])\n","X = np.asarray(val_words)\n","X = pad_sequences(X, maxlen=4)\n","X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17540, 4)"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"OOsOy9dSghEB"},"source":["# second word prediction in pred_2\n","pred = model_1.predict(X)\n","pred_2 = []\n","for i in range(pred.shape[0]):\n","  pred_2.append(np.argmax(pred[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8uCJEZMgjMn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623403144741,"user_tz":-330,"elapsed":18,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"9dee70a2-c7d7-44c7-d1fa-c68a72903d7e"},"source":["for i in range(len(val_words)):\n","  val_words[i].append(pred_2[i])\n","X = np.asarray(val_words)\n","X = pad_sequences(X, maxlen=4)\n","X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17540, 4)"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"wk2bQv7ugl_3"},"source":["# third word prediction in pred_3\n","pred = model_1.predict(X)\n","pred_3 = []\n","for i in range(pred.shape[0]):\n","  pred_3.append(np.argmax(pred[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"euUVotqCYGYG"},"source":["*Accuracy prediction*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BEXS7UxvMnj1","executionInfo":{"status":"ok","timestamp":1623403156254,"user_tz":-330,"elapsed":26,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"538dbccd-c551-4304-f7cb-41b0ef0f06eb"},"source":["# create validation predictions for error calculation\n","val_pred = []\n","for i in range(len(pred_1)):\n","  val_pred.extend([pred_1[i],pred_2[i],pred_3[i]])\n","print(len(val_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["52620\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1doqmZiqe4X4","executionInfo":{"status":"ok","timestamp":1623403156254,"user_tz":-330,"elapsed":24,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"7e8587a7-f464-4ae1-dc44-bdcb6511bd23"},"source":["val_target = []\n","for i in range(len(target_val)):\n","  val_target.extend(target_val[i])\n","val_pred = val_pred[:len(val_target)]\n","print(len(val_target))\n","print(val_target[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["52617\n","[21, 41, 4, 41, 4, 28, 4, 28, 374, 28]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CprmFuynOn3v","executionInfo":{"status":"ok","timestamp":1623403156255,"user_tz":-330,"elapsed":19,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"c8dcbe92-e5a5-40d8-dcd3-7e0b4e84a9f8"},"source":["from sklearn.metrics import accuracy_score\n","accuracy = accuracy_score(val_target, val_pred)\n","print(\"Validation Accuracy : %0.2f\"%(accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Validation Accuracy : 6.05\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ySz3yfieXr2N"},"source":["**Cosine Similarity**"]},{"cell_type":"code","metadata":{"id":"zdni8l3cDDVZ"},"source":["cos = 0\n","for j in range(len(val_target)):\n","  for word,i in tokenizer.word_index.items():\n","    if val_target[j]==i:\n","      w1=word\n","      break\n","  for word,i in tokenizer.word_index.items():\n","    if val_pred[j]==i:\n","      w2=word\n","      break    \n","  try:\n","    cos += word2vec.similarity(w1,w2)\n","  except:\n","    cos += 0.5\n","similar = cos/len(val_target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKRujWEm10ZD","executionInfo":{"status":"ok","timestamp":1623403166298,"user_tz":-330,"elapsed":15,"user":{"displayName":"Pratikhya Ranjit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi49WHXlzqfb65uINQEiQSOkTv4LIxAEjXg7FdyLA=s64","userId":"04128595182985293525"}},"outputId":"71b7489f-be9d-4ce0-ef0d-7451a8414345"},"source":["print(cos)\n","print(similar)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["33129.58321860818\n","0.6296364904614132\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4NBhfGACG_MX"},"source":["---\n"]},{"cell_type":"markdown","metadata":{"id":"K_kV2ZdGhdI0"},"source":["**Automated Word Predictor**"]},{"cell_type":"markdown","metadata":{"id":"z8pEv0hGhjnT"},"source":["**Do:**<br>\n","\n","\n","1.   Give a sentence or phrase as the input. It is better to give atleast 4 words for better predictions.\n","2.   Give the target words to obtain prediction accuracy\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Alc4tqEvK9FK"},"source":["Step:<br>\n","1. The input line is split into words and stored as a list\n","2. Target words also the same\n","3. Input and target words converted to sequence of numbers using tokenizer\n","4. Input given to model_1 and first output is stored\n","5. First output is appended with input and given to model_2\n","6. Second output obtained from model_2 is stored and appended to input\n","7. This is given to model_3 and third output is obtained\n","8. All three outputs are converted to string format"]},{"cell_type":"code","metadata":{"id":"ySm8IFuFBsHB"},"source":["while True:\n","  input_line=input(\"Enter a line:\")\n","  if input_line==\"Stop\":\n","    print(\"The End\")\n","    break\n","  else:\n","    target_words=input(\"Enter next words:\")\n","    try:\n","      text_to_pred=[]\n","      pred_words=[]\n","      e_pred=[]\n","      target=[]\n","      for i in input_line.split():\n","        text_to_pred.append(i.lower())\n","      text_pred_seq=tokenizer.texts_to_sequences([text_to_pred])\n","      text_pred_seq=np.array(text_pred_seq)\n","      text_pred_seq=pad_sequences(text_pred_seq,maxlen=train_size-pred_size,dtype=\"int32\",padding='pre',truncating='pre',value=1)\n","      pred_1=np.argmax(model_1.predict(text_pred_seq),axis=-1)\n","      e_pred.append(pred_1[0])\n","\n","      w=my_vocab[pred_1[0]]\n","      pred_words.append(w)\n","      pred_1=np.array([pred_1])\n","      text_pred_seq=np.concatenate((text_pred_seq,pred_1),axis=1)\n","      text_pred_seq=pad_sequences(text_pred_seq,maxlen=train_size-pred_size,dtype=\"int32\",padding='pre',truncating='pre',value=1)\n","\n","      pred_2=np.argmax(model_2.predict(text_pred_seq),axis=-1)\n","      e_pred.append(pred_2[0])\n","      w=my_vocab[pred_2[0]]\n","      pred_words.append(w)\n","      pred_2=np.array([pred_2])\n","      text_pred_seq=np.concatenate((text_pred_seq,pred_2),axis=1)\n","      text_pred_seq=pad_sequences(text_pred_seq,maxlen=train_size-pred_size,dtype=\"int32\",padding='pre',truncating='pre',value=1)\n","\n","      pred_3=np.argmax(model_3.predict(text_pred_seq),axis=-1)\n","      e_pred.append(pred_3[0])\n","      w=my_vocab[pred_3[0]]\n","      pred_words.append(w)\n","      pred_3=np.array([pred_3])\n","\n","      pred=\"\"\n","      for i in pred_words:\n","          pred+=i\n","          pred+=\" \"\n","      # error\n","      p_error = error(target_words,pred)\n","      print(\"Percent error: %0.2f\"%(p_error))     \n","    except:\n","      continue"],"execution_count":null,"outputs":[]}]}